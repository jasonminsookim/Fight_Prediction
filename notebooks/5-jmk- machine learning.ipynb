{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:26.254220Z",
     "start_time": "2019-02-28T16:19:23.373111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/fight_prediction/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import category_encoders as ce\n",
    "\n",
    "# Sklearn Specific\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# sklearn algos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB # Naive Bayes\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier # SGD\n",
    "from sklearn.neural_network import MLPClassifier # neural network (multilayer perceptron)\n",
    "\n",
    "# Bayesian Hyperparameter optimization\n",
    "from hyperopt import hp, tpe, fmin, space_eval\n",
    "\n",
    "# Import Data\n",
    "with open('../data/temp_data/data_dicts.pickle', 'rb') as handle:\n",
    "    data_dicts = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:26.262925Z",
     "start_time": "2019-02-28T16:19:26.256623Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_encode_standardize(df):\n",
    "     # Split features and labels\n",
    "    X = df.iloc[:,4:-1]\n",
    "    X = X.fillna(0)\n",
    "    y = df['result'].astype('int')\n",
    "\n",
    "    # Wrangle \n",
    "    X['f_stance'] = X.apply(lambda x: str(x['f_stance']), axis = 1)\n",
    "    X['o_stance'] = X.apply(lambda x: str(x['o_stance']), axis = 1)\n",
    "\n",
    "    # Encode categorical data\n",
    "    ce_binary = ce.BinaryEncoder(cols = ['f_stance','o_stance'])\n",
    "    X = ce_binary.fit_transform(X, y)\n",
    "    # Scale features with mean = 0 and sd = 1\n",
    "    X = preprocessing.scale(X)\n",
    "    \n",
    "    return(X,y)\n",
    "\n",
    "def without_keys(d, keys):\n",
    "    return {x: d[x] for x in d if x not in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:26.292094Z",
     "start_time": "2019-02-28T16:19:26.268108Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    \"\"\"Objective function to minimize: (1- cross validated test_accuracy_score)\"\"\"\n",
    "    \n",
    "    h_model = params['model']  # Gets the model name\n",
    "    del params['model'] # Gets the hyperparameters\n",
    "    \n",
    "    # Initialize model with parameters\n",
    "    if h_model == \"RandomForestClassifier\":\n",
    "        model = RandomForestClassifier(**params)\n",
    "    elif h_model == \"KNeighborsClassifier\":\n",
    "        model = KNeighborsClassifier(**params)\n",
    "    elif h_model == \"LogisticRegression\":\n",
    "        model = LogisticRegression(**params)\n",
    "    \n",
    "    scoring_stats = {'accuracy': 'accuracy',\n",
    "               'recall': 'recall',\n",
    "               'precision': 'precision',\n",
    "               'roc_auc': 'roc_auc'}\n",
    "    \n",
    "    avg_scores = cross_validate(model, X, y, cv=5, scoring = scoring_stats)\n",
    "\n",
    "    cv_accuracy = np.mean(avg_scores['test_accuracy'])\n",
    "    return(1 - cv_accuracy)\n",
    "\n",
    "def get_space(model):\n",
    "    model_name = type(model).__name__\n",
    "    \n",
    "            \n",
    "    if model_name == \"LogisticRegression\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'dual': hp.choice('dual', [True,False])}\n",
    "        \n",
    "    elif model_name == \"RandomForestClassifier\":\n",
    "        space_dict = {'model' : model_name,\n",
    "                      'max_depth': hp.choice('max_depth', range(1,50)),\n",
    "                      'max_features': hp.choice('max_features', range(1,50)),\n",
    "                      'n_estimators': hp.choice('n_estimators', range(1,50)),}\n",
    "        \n",
    "    elif model_name == \"svm.SVC\": # Fix space dict\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100))}\n",
    "        \n",
    "    elif model_name == \"KNeighborsClassifier\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100)),\n",
    "                      'weights': hp.choice('leaf_size', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "                      'leaf_size': hp.choice('leaf_size', range(1,60))}\n",
    "    \n",
    "    elif model_name == \"DecisionTreeClassifier\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100))}\n",
    "    \n",
    "    elif model_name == \"GaussianNB\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100))}\n",
    "    \n",
    "    elif model_name == \"Perceptron\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100))}\n",
    "    \n",
    "    elif model_name == \"SGDClassifier\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100))}\n",
    "    \n",
    "    elif model_name == \"MLPClassifier\":\n",
    "        space_dict = {'model': model_name,\n",
    "                      'n_neighbors': hp.choice('n_neighbors', range(1,100))}\n",
    "    \n",
    "\n",
    "    return(space_dict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:26.305320Z",
     "start_time": "2019-02-28T16:19:26.297623Z"
    }
   },
   "outputs": [],
   "source": [
    "# blr_clf = LogisticRegression()\n",
    "# rf_clf = RandomForestClassifier()\n",
    "# svm_clf = svm.SVC()\n",
    "# knn_clf = KNeighborsClassifier()\n",
    "# dtree_clf = DecisionTreeClassifier()\n",
    "# nb_clf = GaussianNB()\n",
    "# perc_clf = Perceptron()\n",
    "# sgd_clf = SGDClassifier()\n",
    "# mlp_clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Initialize Models and Generate Dictionary for Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T23:06:08.422931Z",
     "start_time": "2019-02-27T23:06:08.415073Z"
    }
   },
   "source": [
    "# Initialize models\n",
    "models = []\n",
    "\n",
    "blr_clf = LogisticRegression()\n",
    "rf_clf = RandomForestClassifier()\n",
    "svm_clf = svm.SVC()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "dtree_clf = DecisionTreeClassifier()\n",
    "nb_clf = GaussianNB()\n",
    "perc_clf = Perceptron()\n",
    "sgd_clf = SGDClassifier()\n",
    "mlp_clf = MLPClassifier()\n",
    "\n",
    "# add models to a list\n",
    "models.extend((blr_clf ,rf_clf, svm_clf, knn_clf, dtree_clf, nb_clf, perc_clf, sgd_clf,mlp_clf))\n",
    "\n",
    "# Initialize a dictionary for scores, dataset\n",
    "score_d = {}\n",
    "score_d['dict_type'] = []\n",
    "score_d['dataset'] = []\n",
    "score_d['num_obs'] = []\n",
    "score_d['model_name'] = []\n",
    "score_d['accuracy'] = []\n",
    "score_d['precision'] = []\n",
    "score_d['recall'] = []\n",
    "score_d['roc_auc'] = []\n",
    "score_d['hp_dict'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:27.088996Z",
     "start_time": "2019-02-28T16:19:27.080976Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = []\n",
    "\n",
    "blr_clf = LogisticRegression()\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# add models to a list\n",
    "models.extend((rf_clf, blr_clf))\n",
    "\n",
    "# Initialize a dictionary for scores, dataset\n",
    "score_d = {}\n",
    "score_d['dict_type'] = []\n",
    "score_d['dataset'] = []\n",
    "score_d['num_obs'] = []\n",
    "score_d['model_name'] = []\n",
    "score_d['accuracy'] = []\n",
    "score_d['precision'] = []\n",
    "score_d['recall'] = []\n",
    "score_d['roc_auc'] = []\n",
    "score_d['hp_dict'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-19T22:22:42.533946Z",
     "start_time": "2019-02-19T22:22:42.530068Z"
    }
   },
   "source": [
    "# 5. Train and print scores for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:28.167253Z",
     "start_time": "2019-02-28T16:19:28.163710Z"
    }
   },
   "outputs": [],
   "source": [
    "cumu_dfs_dict = data_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:19:28.453220Z",
     "start_time": "2019-02-28T16:19:28.435742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cumu_dfs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:37:01.566523Z",
     "start_time": "2019-02-28T16:19:28.996258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [04:05<00:00,  7.11s/it, best loss: 0.40527550755794983]\n",
      "{'max_depth': 10, 'max_features': 15, 'model': 'RandomForestClassifier', 'n_estimators': 39}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:28<00:00,  1.03it/s, best loss: 0.43968571978283966]\n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [03:30<00:00, 15.80s/it, best loss: 0.42331799777069246]\n",
      "{'max_depth': 36, 'max_features': 44, 'model': 'RandomForestClassifier', 'n_estimators': 49}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.50it/s, best loss: 0.4542601079559164]\n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [02:15<00:00,  8.74s/it, best loss: 0.41616446020262055]\n",
      "{'max_depth': 41, 'max_features': 22, 'model': 'RandomForestClassifier', 'n_estimators': 49}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:10<00:00,  2.07it/s, best loss: 0.4547748199490437]\n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [01:27<00:00,  4.72s/it, best loss: 0.42789030906990166]\n",
      "{'max_depth': 11, 'max_features': 8, 'model': 'RandomForestClassifier', 'n_estimators': 42}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.08it/s, best loss: 0.4413988782977085]\n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [00:59<00:00,  2.31s/it, best loss: 0.4484028705765899] \n",
      "{'max_depth': 18, 'max_features': 18, 'model': 'RandomForestClassifier', 'n_estimators': 44}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:05<00:00,  4.05it/s, best loss: 0.4648582034149963] \n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [00:58<00:00,  2.46s/it, best loss: 0.4398049855622358]\n",
      "{'max_depth': 19, 'max_features': 19, 'model': 'RandomForestClassifier', 'n_estimators': 27}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.26it/s, best loss: 0.45434971113222045]\n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [00:33<00:00,  1.44s/it, best loss: 0.45548645944947674]\n",
      "{'max_depth': 45, 'max_features': 45, 'model': 'RandomForestClassifier', 'n_estimators': 36}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:03<00:00,  7.25it/s, best loss: 0.40720054585923804]\n",
      "{'dual': False, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [00:34<00:00,  1.34s/it, best loss: 0.45798591281172674]\n",
      "{'max_depth': 33, 'max_features': 13, 'model': 'RandomForestClassifier', 'n_estimators': 40}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:03<00:00,  6.87it/s, best loss: 0.4375975632971636]\n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [00:23<00:00,  1.26it/s, best loss: 0.4396436492758662]\n",
      "{'max_depth': 44, 'max_features': 20, 'model': 'RandomForestClassifier', 'n_estimators': 18}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:02<00:00,  8.55it/s, best loss: 0.4259348411331152] \n",
      "{'dual': True, 'model': 'LogisticRegression'}\n",
      "RandomForestClassifier\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.11it/s, best loss: 0.44416212946158506]\n",
      "{'max_depth': 24, 'max_features': 44, 'model': 'RandomForestClassifier', 'n_estimators': 32}\n",
      "LogisticRegression\n",
      "100%|██████████| 25/25 [00:02<00:00, 12.15it/s, best loss: 0.4333635813672112]\n",
      "{'dual': False, 'model': 'LogisticRegression'}\n"
     ]
    }
   ],
   "source": [
    "df_index = 0\n",
    "for key in cumu_dfs_dict:\n",
    "    df_index += 1\n",
    "    \n",
    "    if (df_index <= 10):\n",
    "        continue\n",
    "    \n",
    "    dict_type = \"cumu_dfs_dict\"\n",
    "    df = cumu_dfs_dict[key].copy()\n",
    "\n",
    "    dataset = key\n",
    "    num_obs = df.shape[0]\n",
    "\n",
    "    X,y = split_encode_standardize(df)\n",
    "\n",
    "    for model in models:\n",
    "        model_name = type(model).__name__\n",
    "        \n",
    "        print(model_name)\n",
    "        \n",
    "        space = get_space(model)\n",
    "        best_h = fmin(fn=objective_function, space=space, algo=tpe.suggest, max_evals=25)\n",
    "        opt_hp = space_eval(space, best_h)\n",
    "        \n",
    "        print(opt_hp)\n",
    "        del opt_hp['model']\n",
    "        \n",
    "        # create new model with tuned hyperparameters\n",
    "        if model_name == \"RandomForestClassifier\":\n",
    "            ht_model = RandomForestClassifier(**opt_hp)\n",
    "        \n",
    "        elif model_name == \"KNeighborsClassifier\":\n",
    "            ht_model = KNeighborsClassifier(**opt_hp)\n",
    "        \n",
    "        elif model_name == \"LogisticRegression\":\n",
    "            ht_model = LogisticRegression(**opt_hp)\n",
    "        \n",
    "    \n",
    "        scoring_stats = {'accuracy': 'accuracy',\n",
    "               'recall': 'recall',\n",
    "               'precision': 'precision',\n",
    "               'roc_auc': 'roc_auc'}    \n",
    "        \n",
    "        \n",
    "\n",
    "        # Calculate scores\n",
    "        avg_scores = cross_validate(ht_model, X, y, cv=5, scoring = scoring_stats)\n",
    "\n",
    "        accuracy = np.mean(avg_scores['test_accuracy'])\n",
    "        precision = np.mean(avg_scores['test_precision'])\n",
    "        recall = np.mean(avg_scores['test_recall'])\n",
    "        roc_auc = np.mean(avg_scores['test_roc_auc'])\n",
    "\n",
    "        # append to dictionary\n",
    "        score_d['dict_type'].append(dict_type)\n",
    "        score_d['dataset'].append(dataset)\n",
    "        score_d['num_obs'].append(num_obs)\n",
    "        score_d['model_name'].append(model_name)\n",
    "        score_d['accuracy'].append(accuracy)\n",
    "        score_d['precision'].append(precision)\n",
    "        score_d['recall'].append(recall)\n",
    "        score_d['roc_auc'].append(roc_auc)\n",
    "        score_d['hp_dict'].append(opt_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:37:28.942172Z",
     "start_time": "2019-02-28T16:37:28.912562Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dict_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 1 Fight Lookback Window</td>\n",
       "      <td>6914</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.589087</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>0.565246</td>\n",
       "      <td>0.618410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 1 Fight Lookback Window</td>\n",
       "      <td>6914</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.552505</td>\n",
       "      <td>0.549287</td>\n",
       "      <td>0.504708</td>\n",
       "      <td>0.573533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 2 Fight Lookback Window</td>\n",
       "      <td>5006</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.569498</td>\n",
       "      <td>0.566291</td>\n",
       "      <td>0.535040</td>\n",
       "      <td>0.590993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 2 Fight Lookback Window</td>\n",
       "      <td>5006</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.542940</td>\n",
       "      <td>0.539227</td>\n",
       "      <td>0.502649</td>\n",
       "      <td>0.560074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 3 Fight Lookback Window</td>\n",
       "      <td>3780</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.573261</td>\n",
       "      <td>0.567054</td>\n",
       "      <td>0.557795</td>\n",
       "      <td>0.599265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 3 Fight Lookback Window</td>\n",
       "      <td>3780</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.542579</td>\n",
       "      <td>0.537529</td>\n",
       "      <td>0.504569</td>\n",
       "      <td>0.559633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 4 Fight Lookback Window</td>\n",
       "      <td>2884</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.557544</td>\n",
       "      <td>0.551661</td>\n",
       "      <td>0.540845</td>\n",
       "      <td>0.575129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 4 Fight Lookback Window</td>\n",
       "      <td>2884</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.557558</td>\n",
       "      <td>0.551930</td>\n",
       "      <td>0.538028</td>\n",
       "      <td>0.584160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 5 Fight Lookback Window</td>\n",
       "      <td>2248</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.533346</td>\n",
       "      <td>0.526007</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.552977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 5 Fight Lookback Window</td>\n",
       "      <td>2248</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.527584</td>\n",
       "      <td>0.519745</td>\n",
       "      <td>0.508597</td>\n",
       "      <td>0.558876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 6 Fight Lookback Window</td>\n",
       "      <td>1710</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.518096</td>\n",
       "      <td>0.511542</td>\n",
       "      <td>0.483326</td>\n",
       "      <td>0.526149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 6 Fight Lookback Window</td>\n",
       "      <td>1710</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.542726</td>\n",
       "      <td>0.536507</td>\n",
       "      <td>0.523795</td>\n",
       "      <td>0.564275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 7 Fight Lookback Window</td>\n",
       "      <td>1348</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.522958</td>\n",
       "      <td>0.517877</td>\n",
       "      <td>0.461381</td>\n",
       "      <td>0.523572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 7 Fight Lookback Window</td>\n",
       "      <td>1348</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.592799</td>\n",
       "      <td>0.586972</td>\n",
       "      <td>0.571930</td>\n",
       "      <td>0.586204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 8 Fight Lookback Window</td>\n",
       "      <td>1026</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.532191</td>\n",
       "      <td>0.526120</td>\n",
       "      <td>0.475109</td>\n",
       "      <td>0.536337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 8 Fight Lookback Window</td>\n",
       "      <td>1026</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.562383</td>\n",
       "      <td>0.556366</td>\n",
       "      <td>0.534792</td>\n",
       "      <td>0.585102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 9 Fight Lookback Window</td>\n",
       "      <td>782</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.538413</td>\n",
       "      <td>0.539417</td>\n",
       "      <td>0.430827</td>\n",
       "      <td>0.542620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 9 Fight Lookback Window</td>\n",
       "      <td>782</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.563899</td>\n",
       "      <td>0.558379</td>\n",
       "      <td>0.532638</td>\n",
       "      <td>0.560484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 10 Fight Lookback Window</td>\n",
       "      <td>572</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.525983</td>\n",
       "      <td>0.517888</td>\n",
       "      <td>0.473120</td>\n",
       "      <td>0.558705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cumu_dfs_dict</td>\n",
       "      <td>Cumulative Data: 10 Fight Lookback Window</td>\n",
       "      <td>572</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.566636</td>\n",
       "      <td>0.561371</td>\n",
       "      <td>0.548246</td>\n",
       "      <td>0.574054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dict_type                                    dataset  num_obs  \\\n",
       "0   cumu_dfs_dict   Cumulative Data: 1 Fight Lookback Window     6914   \n",
       "1   cumu_dfs_dict   Cumulative Data: 1 Fight Lookback Window     6914   \n",
       "2   cumu_dfs_dict   Cumulative Data: 2 Fight Lookback Window     5006   \n",
       "3   cumu_dfs_dict   Cumulative Data: 2 Fight Lookback Window     5006   \n",
       "4   cumu_dfs_dict   Cumulative Data: 3 Fight Lookback Window     3780   \n",
       "5   cumu_dfs_dict   Cumulative Data: 3 Fight Lookback Window     3780   \n",
       "6   cumu_dfs_dict   Cumulative Data: 4 Fight Lookback Window     2884   \n",
       "7   cumu_dfs_dict   Cumulative Data: 4 Fight Lookback Window     2884   \n",
       "8   cumu_dfs_dict   Cumulative Data: 5 Fight Lookback Window     2248   \n",
       "9   cumu_dfs_dict   Cumulative Data: 5 Fight Lookback Window     2248   \n",
       "10  cumu_dfs_dict   Cumulative Data: 6 Fight Lookback Window     1710   \n",
       "11  cumu_dfs_dict   Cumulative Data: 6 Fight Lookback Window     1710   \n",
       "12  cumu_dfs_dict   Cumulative Data: 7 Fight Lookback Window     1348   \n",
       "13  cumu_dfs_dict   Cumulative Data: 7 Fight Lookback Window     1348   \n",
       "14  cumu_dfs_dict   Cumulative Data: 8 Fight Lookback Window     1026   \n",
       "15  cumu_dfs_dict   Cumulative Data: 8 Fight Lookback Window     1026   \n",
       "16  cumu_dfs_dict   Cumulative Data: 9 Fight Lookback Window      782   \n",
       "17  cumu_dfs_dict   Cumulative Data: 9 Fight Lookback Window      782   \n",
       "18  cumu_dfs_dict  Cumulative Data: 10 Fight Lookback Window      572   \n",
       "19  cumu_dfs_dict  Cumulative Data: 10 Fight Lookback Window      572   \n",
       "\n",
       "                model_name  accuracy  precision    recall   roc_auc  \n",
       "0   RandomForestClassifier  0.589087   0.585427  0.565246  0.618410  \n",
       "1       LogisticRegression  0.552505   0.549287  0.504708  0.573533  \n",
       "2   RandomForestClassifier  0.569498   0.566291  0.535040  0.590993  \n",
       "3       LogisticRegression  0.542940   0.539227  0.502649  0.560074  \n",
       "4   RandomForestClassifier  0.573261   0.567054  0.557795  0.599265  \n",
       "5       LogisticRegression  0.542579   0.537529  0.504569  0.559633  \n",
       "6   RandomForestClassifier  0.557544   0.551661  0.540845  0.575129  \n",
       "7       LogisticRegression  0.557558   0.551930  0.538028  0.584160  \n",
       "8   RandomForestClassifier  0.533346   0.526007  0.505882  0.552977  \n",
       "9       LogisticRegression  0.527584   0.519745  0.508597  0.558876  \n",
       "10  RandomForestClassifier  0.518096   0.511542  0.483326  0.526149  \n",
       "11      LogisticRegression  0.542726   0.536507  0.523795  0.564275  \n",
       "12  RandomForestClassifier  0.522958   0.517877  0.461381  0.523572  \n",
       "13      LogisticRegression  0.592799   0.586972  0.571930  0.586204  \n",
       "14  RandomForestClassifier  0.532191   0.526120  0.475109  0.536337  \n",
       "15      LogisticRegression  0.562383   0.556366  0.534792  0.585102  \n",
       "16  RandomForestClassifier  0.538413   0.539417  0.430827  0.542620  \n",
       "17      LogisticRegression  0.563899   0.558379  0.532638  0.560484  \n",
       "18  RandomForestClassifier  0.525983   0.517888  0.473120  0.558705  \n",
       "19      LogisticRegression  0.566636   0.561371  0.548246  0.574054  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict = without_keys(score_d, 'hp_dict')\n",
    "scores_df = pd.DataFrame(scores_dict)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T16:37:33.408567Z",
     "start_time": "2019-02-28T16:37:33.398772Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df.to_csv(\"../data/partial_scores_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Analysis\n",
    "- The hyperparameters from the sklearn classifiers were set to their defaults and will be tuned. \n",
    "\n",
    "\n",
    "- Nevertheless, the effectiveness of each model appears to vary based off the length of the look back number. I will soon be transforming the printed text data above into nicer looking graphs.  \n",
    "\n",
    "\n",
    "- Please scroll around in the above cell to view the accuracy, recall, precision, and ROC-AUC from using a cross validate method. \n",
    "\n",
    "\n",
    "- Now, most of the accuracy percentages are hovering near the 50% mark. As noted by previous literature, this data is inherently noisy and will likely make it very difficult to have an accuracy of over 60%. It is even more of an issue when generating the data using a look back window because the number of observations decreases substantially. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fight_prediction]",
   "language": "python",
   "name": "conda-env-fight_prediction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
